{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVM\n",
      "Accuracy: 0.9545454545454546\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: MLP\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: SGD\n",
      "Accuracy: 0.9545454545454546\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.7272727272727273\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73        14\n",
      "           1       0.57      1.00      0.73         8\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.79      0.79      0.73        22\n",
      "weighted avg       0.84      0.73      0.73        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Malco\\mambaforge\\envs\\data\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Handle Missing Values\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == 'object':  # Categorical column\n",
    "            data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "        else:  # Numerical column\n",
    "            data[column].fillna(data[column].mean(), inplace=True)\n",
    "    \n",
    "    # Handle Categorical Variables\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if len(data[column].unique()) <= 2:  # Binary categorical column\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "        else:  # Multi-class categorical column\n",
    "            data = pd.get_dummies(data, columns=[column], drop_first=True)\n",
    "    \n",
    "    # Standardize/Normalize Data\n",
    "    scaler = StandardScaler()\n",
    "    numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the Dataset\n",
    "data_path = \"C:/Users/Malco/OneDrive/Desktop/No-Code Project Classification/Obesity Classification.csv\"  \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess the Data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Convert the target variable to integer type\n",
    "y = data.iloc[:, -1].astype(int)\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X = data.iloc[:, :-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and Train Multiple Classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"SGD\": SGDClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    results[name] = (accuracy, report)\n",
    "\n",
    "# Evaluate and Display Results\n",
    "for name, (accuracy, report) in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVM\n",
      "Accuracy: 0.8688845401174168\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       869\n",
      "           2       0.66      0.26      0.37       153\n",
      "\n",
      "    accuracy                           0.87      1022\n",
      "   macro avg       0.77      0.62      0.65      1022\n",
      "weighted avg       0.85      0.87      0.84      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: MLP\n",
      "Accuracy: 0.8610567514677103\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       869\n",
      "           2       0.54      0.45      0.49       153\n",
      "\n",
      "    accuracy                           0.86      1022\n",
      "   macro avg       0.72      0.69      0.71      1022\n",
      "weighted avg       0.85      0.86      0.86      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: SGD\n",
      "Accuracy: 0.8522504892367906\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       869\n",
      "           2       0.51      0.41      0.45       153\n",
      "\n",
      "    accuracy                           0.85      1022\n",
      "   macro avg       0.70      0.67      0.68      1022\n",
      "weighted avg       0.84      0.85      0.85      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.8287671232876712\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89       869\n",
      "           2       0.47      1.00      0.64       153\n",
      "\n",
      "    accuracy                           0.83      1022\n",
      "   macro avg       0.73      0.90      0.76      1022\n",
      "weighted avg       0.92      0.83      0.85      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.8493150684931506\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       869\n",
      "           2       0.50      0.50      0.50       153\n",
      "\n",
      "    accuracy                           0.85      1022\n",
      "   macro avg       0.70      0.71      0.71      1022\n",
      "weighted avg       0.85      0.85      0.85      1022\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Malco\\mambaforge\\envs\\data\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Handle Missing Values\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == 'object':  # Categorical column\n",
    "            data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "        else:  # Numerical column\n",
    "            data[column].fillna(data[column].mean(), inplace=True)\n",
    "    \n",
    "    # Handle Categorical Variables\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if len(data[column].unique()) <= 2:  # Binary categorical column\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "        else:  # Multi-class categorical column\n",
    "            data = pd.get_dummies(data, columns=[column], drop_first=True)\n",
    "    \n",
    "    # Standardize/Normalize Data\n",
    "    scaler = StandardScaler()\n",
    "    numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the Dataset\n",
    "data_path = \"C:/Users/Malco/OneDrive/Desktop/No-Code Project Classification/healthcare-dataset-stroke-data.csv\"  \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess the Data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Convert the target variable to integer type\n",
    "y = data.iloc[:, -1].astype(int)\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X = data.iloc[:, :-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and Train Multiple Classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"SGD\": SGDClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    results[name] = (accuracy, report)\n",
    "\n",
    "# Evaluate and Display Results\n",
    "for name, (accuracy, report) in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVM\n",
      "Accuracy: 0.9545454545454546\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: MLP\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: SGD\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.7272727272727273\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73        14\n",
      "           1       0.57      1.00      0.73         8\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.79      0.79      0.73        22\n",
      "weighted avg       0.84      0.73      0.73        22\n",
      "\n",
      "--------------------------------------------------\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Malco\\mambaforge\\envs\\data\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder  # For data preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score  # For evaluating classifier performance\n",
    "from sklearn.svm import SVC  # Support Vector Machine classifier\n",
    "from sklearn.neural_network import MLPClassifier  # Multi-layer Perceptron classifier\n",
    "from sklearn.linear_model import SGDClassifier  # Stochastic Gradient Descent classifier\n",
    "from sklearn.naive_bayes import GaussianNB  # Gaussian Naive Bayes classifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree classifier\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(data):\n",
    "    # Handle Missing Values\n",
    "    for column in data.columns:  # Loop through each column in the dataset\n",
    "        # Check if the column is categorical (object type)\n",
    "        if data[column].dtype == 'object':\n",
    "            # Fill missing values with the mode (most frequent value) of the column\n",
    "            data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "        else:  # If the column is numerical\n",
    "            # Fill missing values with the mean (average) of the column\n",
    "            data[column].fillna(data[column].mean(), inplace=True)\n",
    "    \n",
    "    # Handle Categorical Variables\n",
    "    # Identify columns that are of object type (categorical)\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:  # Loop through each categorical column\n",
    "        # Check if the column is binary (has only 2 unique values)\n",
    "        if len(data[column].unique()) <= 2:\n",
    "            le = LabelEncoder()  # Initialize a label encoder\n",
    "            # Convert the column values to numerical labels\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "        else:  # If the column has more than 2 unique values\n",
    "            # Convert the column to one-hot encoded columns\n",
    "            data = pd.get_dummies(data, columns=[column], drop_first=True)\n",
    "    \n",
    "    # Standardize/Normalize Data\n",
    "    scaler = StandardScaler()  # Initialize a standard scaler\n",
    "    # Identify columns that are not of object type (numerical)\n",
    "    numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
    "    # Standardize the numerical columns\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "    \n",
    "    return data  # Return the preprocessed data\n",
    "\n",
    "# Load the Dataset from the specified path\n",
    "data_path = \"C:/Users/Malco/OneDrive/Desktop/No-Code Project Classification/Obesity Classification.csv\"  \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess the Data using the defined function\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Convert the target variable (last column) to integer type\n",
    "y = data.iloc[:, -1].astype(int)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.iloc[:, :-1]\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a dictionary of classifiers to be used\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"SGD\": SGDClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "results = {}  # Dictionary to store results for each classifier\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)  # Train the classifier on the training data\n",
    "    y_pred = clf.predict(X_test)  # Predict the target variable for the test data\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate the accuracy of the classifier\n",
    "    report = classification_report(y_test, y_pred)  # Generate a classification report\n",
    "    results[name] = (accuracy, report)  # Store the results in the results dictionary\n",
    "\n",
    "# Display the results for each classifier\n",
    "for name, (accuracy, report) in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
